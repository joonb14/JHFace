{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow ArcFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref https://github.com/peteryuX/arcface-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from models import ArcFaceModel\n",
    "# from losses import SoftmaxLoss\n",
    "from losses import softmax_loss\n",
    "import dataset\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4658122\n",
      "36391\n",
      "1164531\n",
      "9097\n"
     ]
    }
   ],
   "source": [
    "### IJB-C Dataset\n",
    "\n",
    "# batch_size = 128\n",
    "# input_size = 112\n",
    "# embd_shape = 512\n",
    "# head_type = 'ArcHead'\n",
    "# backbone_type = 'MobileNetV2'\n",
    "# w_decay=5e-4\n",
    "# num_classes = 3584 \n",
    "# base_lr = 0.01\n",
    "# dataset_len = 13033 \n",
    "# epochs = 100\n",
    "# steps_per_epoch = dataset_len // batch_size\n",
    "\n",
    "### MS1M dataset\n",
    "\n",
    "batch_size = 128 # Initially 128\n",
    "input_size = 112\n",
    "embd_shape = 512\n",
    "head_type = 'CosHead' # 'ArcHead', 'CosHead'\n",

    "# Backbones w/ pretrained weights:\n",
    "#     MobileNet, MobileNetV2, InceptionResNetV2, InceptionV3, ResNet50, ResNet50V2, ResNet101V2, NASNetLarge, NASNetMobile, Xception\n",
    "#     But if you are trying to use NasNet, please check this issue first: https://github.com/keras-team/keras-applications/issues/78\n",
    "#         We manually download the weight file and explicitly load it in models.py file\n",
    "# Backbones w/o pretrained weights:\n",
    "#     MobileNetV3Large, MobileNetV3Small, EfficientNetLite0~6, EfficientNetB0~7\n",
    "backbone_type = 'InceptionResNetV2' \n",
    "w_decay=5e-4\n",
    "num_classes = 85742 \n",
    "dataset_len = 5822653 \n",
    "base_lr = 0.01 # initially 0.01\n",
    "epochs = 20\n",
    "save_steps = 1000\n",
    "train_size = int(0.8 * dataset_len)\n",
    "print(train_size)\n",
    "steps_per_epoch = train_size // batch_size\n",
    "print(steps_per_epoch)\n",
    "val_size = dataset_len - train_size\n",
    "print(val_size)\n",
    "validation_steps = val_size // batch_size\n",
    "print(validation_steps)\n",
    "steps = 1\n",
    "is_ccrop=False\n",
    "binary_img=True\n",
    "is_Adam = False\n",
    "\n",
    "dgx = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 3s 0us/step\n",
      "Model: \"arcface_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_resnet_v2 (Functional (None, 2, 2, 1536)   54336736    input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "OutputLayer (Functional)        (None, 512)          3154432     inception_resnet_v2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "label (InputLayer)              [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ArcHead (Functional)            (None, 85742)        43899904    OutputLayer[0][0]                \n",
      "                                                                 label[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 101,391,072\n",
      "Trainable params: 101,326,432\n",
      "Non-trainable params: 64,640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train_data_dir = \"/raid/workspace/jbpark/IJB-C_Asian/\"\n",
    "# tfrecord_name = train_data_dir+'ijbc_bin.tfrecord'\n",
    "if dgx:\n",
    "    train_data_dir = \"/raid/workspace/jbpark/ms1m/\"\n",
    "    tfrecord_name = train_data_dir+'ms1m_bin.tfrecord'\n",
    "else:\n",
    "    train_data_dir = \"/hd/jbpark/dataset/ms1m/\"\n",
    "    tfrecord_name = train_data_dir+'ms1m_bin.tfrecord'\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = dataset.load_tfrecord_dataset(\n",
    "    tfrecord_name, batch_size, train_size=train_size, binary_img=binary_img, \n",
    "    is_ccrop=is_ccrop)\n",
    "\n",
    "if dgx:\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:2\"])\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "#     strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "with strategy.scope():\n",
    "    model = ArcFaceModel(size=input_size,\n",
    "                             backbone_type=backbone_type,\n",
    "                             num_classes=num_classes,\n",
    "                             head_type=head_type,\n",
    "                             embd_shape=embd_shape,\n",
    "                             w_decay=w_decay,\n",
    "                             training=True)\n",
    "    model.summary()\n",
    "\n",
    "    learning_rate = tf.constant(base_lr)\n",
    "    if is_Adam:\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate)\n",
    "\n",
    "    loss_fn = softmax_loss\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1000/36391 [..............................] - ETA: 2:17:41 - loss: 46.2284\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_45.90513229370117.ckpt\n",
      " 2000/36391 [>.............................] - ETA: 2:11:57 - loss: 45.8746\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_45.135643005371094.ckpt\n",
      " 3000/36391 [=>............................] - ETA: 2:07:19 - loss: 45.5020\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_44.3824577331543.ckpt\n",
      " 4000/36391 [==>...........................] - ETA: 2:02:38 - loss: 45.1306\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_43.65995788574219.ckpt\n",
      " 5000/36391 [===>..........................] - ETA: 1:58:40 - loss: 44.7666\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_42.96448516845703.ckpt\n",
      " 6000/36391 [===>..........................] - ETA: 1:53:31 - loss: 44.4101\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_42.29669189453125.ckpt\n",
      " 7000/36391 [====>.........................] - ETA: 1:48:35 - loss: 44.0618\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_41.651893615722656.ckpt\n",
      " 8000/36391 [=====>........................] - ETA: 1:44:07 - loss: 43.7210\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_41.02336502075195.ckpt\n",
      " 9000/36391 [======>.......................] - ETA: 1:40:33 - loss: 43.3873\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_40.414512634277344.ckpt\n",
      "10000/36391 [=======>......................] - ETA: 1:36:27 - loss: 43.0599\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_39.814247131347656.ckpt\n",
      "11000/36391 [========>.....................] - ETA: 1:33:29 - loss: 42.7382\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_39.23242950439453.ckpt\n",
      "12000/36391 [========>.....................] - ETA: 1:30:09 - loss: 42.4224\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_38.66386032104492.ckpt\n",
      "13000/36391 [=========>....................] - ETA: 1:26:26 - loss: 42.1116\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_38.10419845581055.ckpt\n",
      "14000/36391 [==========>...................] - ETA: 1:22:27 - loss: 41.8057\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_37.55704879760742.ckpt\n",
      "15000/36391 [===========>..................] - ETA: 1:18:28 - loss: 41.5044\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_37.01931381225586.ckpt\n",
      "16000/36391 [============>.................] - ETA: 1:14:42 - loss: 41.2075\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_36.4919319152832.ckpt\n",
      "17000/36391 [=============>................] - ETA: 1:10:57 - loss: 40.9150\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_35.97759246826172.ckpt\n",
      "18000/36391 [=============>................] - ETA: 1:07:22 - loss: 40.6267\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_35.47931671142578.ckpt\n",
      "19000/36391 [==============>...............] - ETA: 1:03:44 - loss: 40.3427\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_34.986454010009766.ckpt\n",
      "20000/36391 [===============>..............] - ETA: 1:00:01 - loss: 40.0629\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_34.50960922241211.ckpt\n",
      "21000/36391 [================>.............] - ETA: 56:22 - loss: 39.7874\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_34.046295166015625.ckpt\n",
      "22000/36391 [=================>............] - ETA: 52:45 - loss: 39.5161\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_33.596885681152344.ckpt\n",
      "23000/36391 [=================>............] - ETA: 49:05 - loss: 39.2492\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_33.16078567504883.ckpt\n",
      "24000/36391 [==================>...........] - ETA: 45:22 - loss: 38.9867\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_32.73789978027344.ckpt\n",
      "25000/36391 [===================>..........] - ETA: 41:40 - loss: 38.7284\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_32.32683181762695.ckpt\n",
      "26000/36391 [====================>.........] - ETA: 37:57 - loss: 38.4745\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_31.92839813232422.ckpt\n",
      "27000/36391 [=====================>........] - ETA: 34:15 - loss: 38.2249\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_31.541770935058594.ckpt\n",
      "28000/36391 [======================>.......] - ETA: 30:35 - loss: 37.9795\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_31.167823791503906.ckpt\n",
      "29000/36391 [======================>.......] - ETA: 26:54 - loss: 37.7383\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_InceptionResNetV2_ArcHead_check/SGD/e_1_l_30.80605125427246.ckpt\n",
      "29121/36391 [=======================>......] - ETA: 26:27 - loss: 37.7094"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if dgx:\n",
    "    base_dir = \"/raid/workspace/honghee/FaceRecognition/\"\n",
    "    # save_name = \"ms1m_mobilenet_check/\"\n",
    "    save_name = \"ms1m_\"+backbone_type+\"_\"+head_type+\"_check/\"\n",
    "else:\n",
    "    base_dir = \"/hd/honghee/models/\"\n",
    "    save_name = \"ms1m_\"+backbone_type+\"_\"+head_type+\"_check/\"\n",
    "\n",
    "if is_Adam:\n",
    "    version = \"Adam\"\n",
    "else:\n",
    "    version = \"SGD\"\n",
    "\n",
    "Path(base_dir + 'checkpoints/w_tfidentity/' + save_name + version).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "### MS1M dataset\n",
    "tb_callback = TensorBoard(log_dir='logs/arcface/',\n",
    "                                  update_freq = batch_size * 5,\n",
    "                                  profile_batch=0)\n",
    "tb_callback._total_batches_seen = steps\n",
    "tb_callback._samples_seen = steps * batch_size\n",
    "mc_callback = ModelCheckpoint(\n",
    "            base_dir + 'checkpoints/w_tfidentity/' + save_name + version +'/e_{epoch}_l_{loss}.ckpt',\n",
    "            save_freq = save_steps, verbose=1,\n",
    "            save_weights_only=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "#                               patience=0.1, min_lr=0.001)\n",
    "# callbacks = [mc_callback, tb_callback,reduce_lr]\n",
    "callbacks = [mc_callback, tb_callback]\n",
    "\n",
    "### IJB-C Dataset\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint(\n",
    "#         base_dir+\"checkpoints/\"+save_name+\".ckpt\", \n",
    "# #         monitor='val_accuracy', \n",
    "#         monitor='loss', \n",
    "#         verbose=1, \n",
    "#         save_best_only=True, \n",
    "#         save_weights_only = True,\n",
    "#         mode='min'\n",
    "#     ),\n",
    "#     EarlyStopping(\n",
    "# #         monitor='val_accuracy', \n",
    "#         monitor='loss', \n",
    "#         patience=15, \n",
    "#         min_delta=0.001, \n",
    "#         mode='min'\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume training with latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_EfficientNetLite0_CosHead_check/SGD/e_1_l_47.875667572021484.ckpt\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "if dgx:\n",
    "    base_dir = \"/raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/\"\n",
    "    # save_name = \"ms1m_mobilenet_check/SGD/*\"\n",
    "    save_name = \"ms1m_\"+backbone_type+\"_\"+head_type+\"_check/\"+version+\"/*\"\n",
    "else:\n",
    "    base_dir = \"/hd/honghee/models/checkpoints/w_tfidentity/\"\n",
    "    save_name = \"ms1m_\"+backbone_type+\"_\"+head_type+\"_check/\"+version+\"/*\"\n",
    "file_list = []\n",
    "for files in glob(base_dir+save_name):\n",
    "    file_list.append(files.split('/')[-1].split('l_')[-1])\n",
    "file_list.sort()\n",
    "\n",
    "load_file_name = []\n",
    "for files in glob(base_dir+save_name):\n",
    "    if file_list[0] == files.split('/')[-1].split('l_')[-1]:\n",
    "        load_file_name = files\n",
    "best_checkpoint = load_file_name.split('.data')[0]\n",
    "initial_epoch = int(load_file_name.split('e_')[-1].split('_')[0])-1\n",
    "print(initial_epoch)\n",
    "print(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"arcface_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-lite0 (Functional) (None, 4, 4, 1280)   3413024     input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "OutputLayer (Functional)        (None, 512)          10493440    efficientnet-lite0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "label (InputLayer)              [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CosHead (Functional)            (None, 85742)        43899904    OutputLayer[0][0]                \n",
      "                                                                 label[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 57,806,368\n",
      "Trainable params: 57,760,768\n",
      "Non-trainable params: 45,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if dgx:\n",
    "    base_dir = \"/raid/workspace/honghee/FaceRecognition/\"\n",
    "    # save_name = \"ms1m_mobilenet_check/\"\n",
    "    save_name = \"ms1m_\"+backbone_type+\"_\"+head_type+\"_check/\"\n",
    "else:\n",
    "    base_dir = \"/hd/honghee/models/\"\n",
    "    save_name = \"ms1m_\"+backbone_type+\"_\"+head_type+\"_check/\"\n",
    "\n",
    "if is_Adam:\n",
    "    version = \"Adam\"\n",
    "else:\n",
    "    version = \"SGD\"\n",
    "\n",
    "Path(base_dir + 'checkpoints/w_tfidentity/' + save_name + version).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# train_data_dir = \"/raid/workspace/jbpark/IJB-C_Asian/\"\n",
    "# tfrecord_name = train_data_dir+'ijbc_bin.tfrecord'\n",
    "\n",
    "if dgx:\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:2\"])\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "#     strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "if dgx:\n",
    "    train_data_dir = \"/raid/workspace/jbpark/ms1m/\"\n",
    "    tfrecord_name = train_data_dir+'ms1m_bin.tfrecord'\n",
    "else:\n",
    "    train_data_dir = \"/hd/jbpark/dataset/ms1m/\"\n",
    "    tfrecord_name = train_data_dir+'ms1m_bin.tfrecord'\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = dataset.load_tfrecord_dataset(\n",
    "    tfrecord_name, batch_size, train_size=train_size, binary_img=binary_img,\n",
    "    is_ccrop=is_ccrop)\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    model = ArcFaceModel(size=input_size,\n",
    "                             backbone_type=backbone_type,\n",
    "                             num_classes=num_classes,\n",
    "                             head_type=head_type,\n",
    "                             embd_shape=embd_shape,\n",
    "                             w_decay=w_decay,\n",
    "                             training=True)\n",
    "    model.load_weights(best_checkpoint)\n",
    "\n",
    "    learning_rate = tf.constant(base_lr)\n",
    "    if is_Adam:\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate)\n",
    "\n",
    "    loss_fn = softmax_loss\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "    model.summary()\n",
    "    \n",
    "tb_callback = TensorBoard(log_dir='logs/arcface/',\n",
    "                                  update_freq = batch_size * 5,\n",
    "                                  profile_batch=0)\n",
    "tb_callback._total_batches_seen = steps\n",
    "tb_callback._samples_seen = steps * batch_size\n",
    "mc_callback = ModelCheckpoint(\n",
    "            base_dir + 'checkpoints/w_tfidentity/' + save_name + version +'/e_{epoch}_l_{loss}.ckpt',\n",
    "            save_freq = save_steps, verbose=1,\n",
    "            save_weights_only=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=1, min_lr=0.001)\n",
    "# callbacks = [mc_callback, tb_callback,reduce_lr]\n",
    "callbacks = [mc_callback, tb_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "    3/36391 [..............................] - ETA: 4:17:41 - loss: 47.6510 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b11aa0bc2114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs, \n",
    "    initial_epoch=initial_epoch,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
