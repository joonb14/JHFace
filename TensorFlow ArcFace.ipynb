{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow ArcFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref https://github.com/peteryuX/arcface-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from models import ArcFaceModel\n",
    "# from losses import SoftmaxLoss\n",
    "from losses import softmax_loss\n",
    "import dataset\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4658122\n",
      "36391\n",
      "1164531\n",
      "9097\n"
     ]
    }
   ],
   "source": [
    "### IJB-C Dataset\n",
    "\n",
    "# batch_size = 128\n",
    "# input_size = 112\n",
    "# embd_shape = 512\n",
    "# head_type = 'ArcHead'\n",
    "# backbone_type = 'MobileNetV2'\n",
    "# w_decay=5e-4\n",
    "# num_classes = 3584 \n",
    "# base_lr = 0.01\n",
    "# dataset_len = 13033 \n",
    "# epochs = 100\n",
    "# steps_per_epoch = dataset_len // batch_size\n",
    "\n",
    "### MS1M dataset\n",
    "\n",
    "batch_size = 128 # Initially 128\n",
    "input_size = 112\n",
    "embd_shape = 512\n",
    "head_type = 'ArcHead'\n",
    "backbone_type = 'EfficientNetLite0' # MobileNetV2, ResNet50, EfficientNetLite0~6\n",
    "w_decay=5e-4\n",
    "num_classes = 85742 \n",
    "dataset_len = 5822653 \n",
    "base_lr = 0.01 # initially 0.01\n",
    "epochs = 20\n",
    "save_steps = 1000\n",
    "train_size = int(0.8 * dataset_len)\n",
    "print(train_size)\n",
    "steps_per_epoch = train_size // batch_size\n",
    "print(steps_per_epoch)\n",
    "val_size = dataset_len - train_size\n",
    "print(val_size)\n",
    "validation_steps = val_size // batch_size\n",
    "print(validation_steps)\n",
    "steps = 1\n",
    "is_ccrop=False\n",
    "binary_img=True\n",
    "is_Adam = False\n",
    "\n",
    "dgx = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"arcface_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-lite0 (Functional) (None, 4, 4, 1280)   3413031     input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "OutputLayer (Functional)        (None, 512)          10493440    efficientnet-lite0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "label (InputLayer)              [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ArcHead (Functional)            (None, 85742)        43899904    OutputLayer[0][0]                \n",
      "                                                                 label[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 57,806,375\n",
      "Trainable params: 57,760,768\n",
      "Non-trainable params: 45,607\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train_data_dir = \"/raid/workspace/jbpark/IJB-C_Asian/\"\n",
    "# tfrecord_name = train_data_dir+'ijbc_bin.tfrecord'\n",
    "if dgx:\n",
    "    train_data_dir = \"/raid/workspace/jbpark/ms1m/\"\n",
    "    tfrecord_name = train_data_dir+'ms1m_bin.tfrecord'\n",
    "else:\n",
    "    train_data_dir = \"/hd/jbpark/dataset/ms1m/\"\n",
    "    tfrecord_name = train_data_dir+'ms1m_bin.tfrecord'\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = dataset.load_tfrecord_dataset(\n",
    "    tfrecord_name, batch_size, train_size=train_size, binary_img=binary_img, \n",
    "    is_ccrop=is_ccrop)\n",
    "\n",
    "if dgx:\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:2\"])\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "#     strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "with strategy.scope():\n",
    "    model = ArcFaceModel(size=input_size,\n",
    "                             backbone_type=backbone_type,\n",
    "                             num_classes=num_classes,\n",
    "                             head_type=head_type,\n",
    "                             embd_shape=embd_shape,\n",
    "                             w_decay=w_decay,\n",
    "                             training=True)\n",
    "    model.summary()\n",
    "\n",
    "    learning_rate = tf.constant(base_lr)\n",
    "    if is_Adam:\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate)\n",
    "\n",
    "    loss_fn = softmax_loss\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1000/36391 [..............................] - ETA: 1:25:07 - loss: 46.5150\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_46.50857162475586.ckpt\n",
      " 2000/36391 [>.............................] - ETA: 1:22:37 - loss: 46.4989\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_46.447227478027344.ckpt\n",
      " 3000/36391 [=>............................] - ETA: 1:19:58 - loss: 46.4639\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_46.33393859863281.ckpt\n",
      " 4000/36391 [==>...........................] - ETA: 1:17:26 - loss: 46.4115\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_46.16621017456055.ckpt\n",
      " 5000/36391 [===>..........................] - ETA: 1:14:56 - loss: 46.3424\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_45.96089553833008.ckpt\n",
      " 6000/36391 [===>..........................] - ETA: 1:12:34 - loss: 46.2605\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_45.741207122802734.ckpt\n",
      " 6009/36391 [===>..........................] - ETA: 1:12:35 - loss: 46.2597"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-742e0686e9a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if dgx:\n",
    "    base_dir = \"/raid/workspace/jbpark/FaceRecognition/\"\n",
    "    # save_name = \"ms1m_mobilenet_check/\"\n",
    "    save_name = \"ms1m_efficientnet_check/\"\n",
    "else:\n",
    "    base_dir = \"/hd/jbpark/models/\"\n",
    "    save_name = \"ms1m_check/\"\n",
    "\n",
    "if is_Adam:\n",
    "    version = \"Adam\"\n",
    "else:\n",
    "    version = \"SGD\"\n",
    "\n",
    "Path(base_dir + 'checkpoints/w_tfidentity/' + save_name + version).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "### MS1M dataset\n",
    "tb_callback = TensorBoard(log_dir='logs/arcface/',\n",
    "                                  update_freq = batch_size * 5,\n",
    "                                  profile_batch=0)\n",
    "tb_callback._total_batches_seen = steps\n",
    "tb_callback._samples_seen = steps * batch_size\n",
    "mc_callback = ModelCheckpoint(\n",
    "            base_dir + 'checkpoints/w_tfidentity/' + save_name + version +'/e_{epoch}_l_{loss}.ckpt',\n",
    "            save_freq = save_steps, verbose=1,\n",
    "            save_weights_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=0.1, min_lr=0.001)\n",
    "callbacks = [mc_callback, tb_callback,reduce_lr]\n",
    "\n",
    "### IJB-C Dataset\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint(\n",
    "#         base_dir+\"checkpoints/\"+save_name+\".ckpt\", \n",
    "# #         monitor='val_accuracy', \n",
    "#         monitor='loss', \n",
    "#         verbose=1, \n",
    "#         save_best_only=True, \n",
    "#         save_weights_only = True,\n",
    "#         mode='min'\n",
    "#     ),\n",
    "#     EarlyStopping(\n",
    "# #         monitor='val_accuracy', \n",
    "#         monitor='loss', \n",
    "#         patience=15, \n",
    "#         min_delta=0.001, \n",
    "#         mode='min'\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume training with latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_38.433876037597656.ckpt\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "if dgx:\n",
    "    base_dir = \"/raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/\"\n",
    "    # save_name = \"ms1m_mobilenet_check/SGD/*\"\n",
    "    save_name = \"ms1m_efficientnet_check/SGD/*\"\n",
    "else:\n",
    "    base_dir = \"/hd/jbpark/models/checkpoints/w_tfidentity/\"\n",
    "    save_name = \"ms1m_check/SGD/*\"\n",
    "file_list = []\n",
    "for files in glob(base_dir+save_name):\n",
    "    file_list.append(files.split('/')[-1].split('l_')[-1])\n",
    "file_list.sort()\n",
    "\n",
    "load_file_name = []\n",
    "for files in glob(base_dir+save_name):\n",
    "    if file_list[0] == files.split('/')[-1].split('l_')[-1]:\n",
    "        load_file_name = files\n",
    "best_checkpoint = load_file_name.split('.data')[0]\n",
    "initial_epoch = int(load_file_name.split('e_')[-1].split('_')[0])-1\n",
    "print(initial_epoch)\n",
    "print(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"arcface_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-lite0 (Functional) (None, 4, 4, 1280)   3413031     input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "OutputLayer (Functional)        (None, 512)          10493440    efficientnet-lite0[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "label (InputLayer)              [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ArcHead (Functional)            (None, 85742)        43899904    OutputLayer[0][0]                \n",
      "                                                                 label[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 57,806,375\n",
      "Trainable params: 57,760,768\n",
      "Non-trainable params: 45,607\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if dgx:\n",
    "    base_dir = \"/raid/workspace/jbpark/FaceRecognition/\"\n",
    "    # save_name = \"ms1m_mobilenet_check/\"\n",
    "    save_name = \"ms1m_efficientnet_check/\"\n",
    "else:\n",
    "    base_dir = \"/hd/jbpark/models/\"\n",
    "    save_name = \"ms1m_check/\"\n",
    "\n",
    "if is_Adam:\n",
    "    version = \"Adam\"\n",
    "else:\n",
    "    version = \"SGD\"\n",
    "\n",
    "Path(base_dir + 'checkpoints/w_tfidentity/' + save_name + version).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# train_data_dir = \"/raid/workspace/jbpark/IJB-C_Asian/\"\n",
    "# tfrecord_name = train_data_dir+'ijbc_bin.tfrecord'\n",
    "\n",
    "if dgx:\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:2\"])\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "#     strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "if dgx:\n",
    "    train_data_dir = \"/raid/workspace/jbpark/ms1m/\"\n",
    "    tfrecord_name = train_data_dir+'ms1m_bin.tfrecord'\n",
    "else:\n",
    "    train_data_dir = \"/hd/jbpark/dataset/ms1m/\"\n",
    "    tfrecord_name = train_data_dir+'ms1m_bin.tfrecord'\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = dataset.load_tfrecord_dataset(\n",
    "    tfrecord_name, batch_size, train_size=train_size, binary_img=binary_img,\n",
    "    is_ccrop=is_ccrop)\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    model = ArcFaceModel(size=input_size,\n",
    "                             backbone_type=backbone_type,\n",
    "                             num_classes=num_classes,\n",
    "                             head_type=head_type,\n",
    "                             embd_shape=embd_shape,\n",
    "                             w_decay=w_decay,\n",
    "                             training=True)\n",
    "    model.load_weights(best_checkpoint)\n",
    "\n",
    "    learning_rate = tf.constant(base_lr)\n",
    "    if is_Adam:\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate)\n",
    "\n",
    "    loss_fn = softmax_loss\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "    model.summary()\n",
    "    \n",
    "tb_callback = TensorBoard(log_dir='logs/arcface/',\n",
    "                                  update_freq = batch_size * 5,\n",
    "                                  profile_batch=0)\n",
    "tb_callback._total_batches_seen = steps\n",
    "tb_callback._samples_seen = steps * batch_size\n",
    "mc_callback = ModelCheckpoint(\n",
    "            base_dir + 'checkpoints/w_tfidentity/' + save_name + version +'/e_{epoch}_l_{loss}.ckpt',\n",
    "            save_freq = save_steps, verbose=1,\n",
    "            save_weights_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)\n",
    "callbacks = [mc_callback, tb_callback,reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1000/36391 [..............................] - ETA: 1:34:10 - loss: 37.4833- ETA\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.47681427001953.ckpt\n",
      " 2000/36391 [>.............................] - ETA: 1:33:45 - loss: 37.4804\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.47140884399414.ckpt\n",
      " 3000/36391 [=>............................] - ETA: 1:31:18 - loss: 37.4735\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.45500183105469.ckpt\n",
      " 4000/36391 [==>...........................] - ETA: 1:28:00 - loss: 37.4906\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.61110305786133.ckpt\n",
      " 5000/36391 [===>..........................] - ETA: 1:24:30 - loss: 37.5222\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.67188262939453.ckpt\n",
      " 6000/36391 [===>..........................] - ETA: 1:21:02 - loss: 37.5489\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.6885871887207.ckpt\n",
      " 7000/36391 [====>.........................] - ETA: 1:17:19 - loss: 37.5687\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.682655334472656.ckpt\n",
      " 8000/36391 [=====>........................] - ETA: 1:14:24 - loss: 37.5818\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.66419982910156.ckpt\n",
      " 9000/36391 [======>.......................] - ETA: 1:12:16 - loss: 37.5894\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.635215759277344.ckpt\n",
      "10000/36391 [=======>......................] - ETA: 1:09:48 - loss: 37.5922\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.59873962402344.ckpt\n",
      "11000/36391 [========>.....................] - ETA: 1:07:24 - loss: 37.5910\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.56026840209961.ckpt\n",
      "12000/36391 [========>.....................] - ETA: 1:04:57 - loss: 37.5868- ETA: 1:04:59 - \n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.519508361816406.ckpt\n",
      "13000/36391 [=========>....................] - ETA: 1:02:37 - loss: 37.5799\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.47522735595703.ckpt\n",
      "14000/36391 [==========>...................] - ETA: 1:00:07 - loss: 37.5708\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.42937088012695.ckpt\n",
      "15000/36391 [===========>..................] - ETA: 57:33 - loss: 37.5598\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.38107681274414.ckpt\n",
      "16000/36391 [============>.................] - ETA: 54:54 - loss: 37.5471\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.33192443847656.ckpt\n",
      "17000/36391 [=============>................] - ETA: 52:21 - loss: 37.5329\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.28059768676758.ckpt\n",
      "18000/36391 [=============>................] - ETA: 49:46 - loss: 37.5175\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.22901153564453.ckpt\n",
      "19000/36391 [==============>...............] - ETA: 47:09 - loss: 37.5009\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.175018310546875.ckpt\n",
      "20000/36391 [===============>..............] - ETA: 44:30 - loss: 37.4832\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.119659423828125.ckpt\n",
      "21000/36391 [================>.............] - ETA: 41:50 - loss: 37.4646\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.06398391723633.ckpt\n",
      "22000/36391 [=================>............] - ETA: 39:09 - loss: 37.4451\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_37.0069465637207.ckpt\n",
      "23000/36391 [=================>............] - ETA: 36:28 - loss: 37.4248\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.94927215576172.ckpt\n",
      "24000/36391 [==================>...........] - ETA: 33:44 - loss: 37.4037\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.88987731933594.ckpt\n",
      "25000/36391 [===================>..........] - ETA: 31:02 - loss: 37.3819\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.82818603515625.ckpt\n",
      "26000/36391 [====================>.........] - ETA: 28:19 - loss: 37.3594\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.76441955566406.ckpt\n",
      "27000/36391 [=====================>........] - ETA: 25:37 - loss: 37.3362\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.6994514465332.ckpt\n",
      "28000/36391 [======================>.......] - ETA: 22:54 - loss: 37.3123\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.633323669433594.ckpt\n",
      "29000/36391 [======================>.......] - ETA: 20:10 - loss: 37.2877\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.56531524658203.ckpt\n",
      "30000/36391 [=======================>......] - ETA: 17:25 - loss: 37.2624\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.49613571166992.ckpt\n",
      "31000/36391 [========================>.....] - ETA: 14:41 - loss: 37.2366\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.4245719909668.ckpt\n",
      "32000/36391 [=========================>....] - ETA: 11:57 - loss: 37.2101\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.351768493652344.ckpt\n",
      "33000/36391 [==========================>...] - ETA: 9:14 - loss: 37.1829\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.27735137939453.ckpt\n",
      "34000/36391 [===========================>..] - ETA: 6:30 - loss: 37.1552\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.201202392578125.ckpt\n",
      "35000/36391 [===========================>..] - ETA: 3:47 - loss: 37.1268\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.12281036376953.ckpt\n",
      "36000/36391 [============================>.] - ETA: 1:03 - loss: 37.0978\n",
      "Epoch 00001: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_1_l_36.042606353759766.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36391/36391 [==============================] - 6193s 170ms/step - loss: 37.0863 - val_loss: 33.0797\n",
      "Epoch 2/20\n",
      "  609/36391 [..............................] - ETA: 1:34:45 - loss: 32.9403\n",
      "Epoch 00002: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_2_l_32.88595199584961.ckpt\n",
      " 1609/36391 [>.............................] - ETA: 1:32:08 - loss: 32.8780\n",
      "Epoch 00002: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_2_l_32.78194808959961.ckpt\n",
      " 2609/36391 [=>............................] - ETA: 1:29:38 - loss: 32.8163\n",
      "Epoch 00002: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_2_l_32.65180969238281.ckpt\n",
      " 3609/36391 [=>............................] - ETA: 1:26:57 - loss: 32.7533\n",
      "Epoch 00002: saving model to /raid/workspace/jbpark/FaceRecognition/checkpoints/w_tfidentity/ms1m_efficientnet_check/SGD/e_2_l_32.5302848815918.ckpt\n",
      " 3986/36391 [==>...........................] - ETA: 1:26:02 - loss: 32.7300"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs, \n",
    "    initial_epoch=initial_epoch,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
