{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Identification Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref https://github.com/peteryuX/arcface-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from models import ArcFaceModel\n",
    "# from losses import SoftmaxLoss\n",
    "from losses import softmax_loss\n",
    "import dataset\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IJB-C Dataset\n",
    "\n",
    "# batch_size = 128\n",
    "# input_size = 112\n",
    "# embd_shape = 512\n",
    "# head_type = 'ArcHead'\n",
    "# backbone_type = 'MobileNetV2'\n",
    "# w_decay=5e-4\n",
    "# num_classes = 3584 \n",
    "# base_lr = 0.01\n",
    "# dataset_len = 13033 \n",
    "# epochs = 100\n",
    "# steps_per_epoch = dataset_len // batch_size\n",
    "\n",
    "### MS1M dataset\n",
    "\n",
    "batch_size = 128 # Initially 128\n",
    "input_size = 112\n",
    "embd_shape = 512\n",
    "head_type = 'ArcHead'\n",
    "backbone_type = 'MobileNetV2'\n",
    "w_decay=5e-4\n",
    "num_classes = 85742 \n",
    "dataset_len = 5822653 \n",
    "base_lr = 0.01 # initially 0.01\n",
    "epochs = 20\n",
    "save_steps = 1000\n",
    "steps_per_epoch = dataset_len // batch_size\n",
    "steps = 1\n",
    "is_ccrop=False\n",
    "binary_img=True\n",
    "is_Adam = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hd/jbpark/models/checkpoints/wo_tfidentity/e_5_l_16.65623664855957.ckpt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "base_dir = \"/hd/jbpark/models/checkpoints/wo_tfidentity/\"\n",
    "save_name = \"e*\"\n",
    "file_list = []\n",
    "for files in glob(base_dir+save_name):\n",
    "    file_list.append(files.split('/')[-1].split('l_')[-1])\n",
    "file_list.sort()\n",
    "\n",
    "load_file_name = []\n",
    "for files in glob(base_dir+save_name):\n",
    "    if file_list[0] == files.split('/')[-1].split('l_')[-1]:\n",
    "        load_file_name = files\n",
    "best_checkpoint = load_file_name.split('.data')[0]\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Face Identification Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"arcface_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_image (InputLayer)     [(None, 112, 112, 3)]     0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 4, 4, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "OutputLayer (Functional)     (None, 512)               10493440  \n",
      "=================================================================\n",
      "Total params: 12,751,424\n",
      "Trainable params: 12,713,728\n",
      "Non-trainable params: 37,696\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from layers import ArcMarginPenaltyLogists\n",
    "from losses import softmax_loss\n",
    "from models import ArcFaceModel\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "weight_file = best_checkpoint\n",
    "\n",
    "model = ArcFaceModel(size=input_size,\n",
    "                         backbone_type=backbone_type,\n",
    "                         training=False)\n",
    "model.load_weights(weight_file)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Embedding Vectors & Create Classifier Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from utils import l2_norm\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_path = \"/hd/jbpark/IJB-C_Asian/Aligned/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3584/3584 [00:00<00:00, 66627.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3584"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from tqdm import tqdm\n",
    "id_list = os.listdir(dataset_path)\n",
    "id_list.sort()\n",
    "source_id = []\n",
    "for id_name in tqdm(id_list):\n",
    "    source_id.append(int(id_list.index(id_name)))\n",
    "len(np.unique(np.array(source_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3584/3584 [05:57<00:00, 10.02it/s]\n"
     ]
    }
   ],
   "source": [
    "subjects = id_list\n",
    "label_int = source_id\n",
    "embed_list = []\n",
    "label_list = []\n",
    "for subject in tqdm(subjects):\n",
    "#     print(\"[*] Encode {} to Embedding Vector ({})\".format(subject,embd_shape))\n",
    "    img_paths = glob(dataset_path+subject+\"/*\")\n",
    "    for img_path in img_paths:\n",
    "#         print(\"[*] Encode {} to ./output_embeds.npy\".format(img))\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (112,112))\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        # print(\"len(img.shape): \"+str(len(img.shape))+ \", img.shape = \"+str(img.shape))\n",
    "        if len(img.shape) == 3:\n",
    "            img = np.expand_dims(img, 0)\n",
    "\n",
    "    #     print(\"len(img.shape): \"+str(len(img.shape))+ \", img.shape = \"+str(img.shape))\n",
    "        embeds = l2_norm(model(img, training=False))\n",
    "    #     embeds.shape\n",
    "    #     embeds\n",
    "        embed_list.append(embeds[0].numpy())\n",
    "        label_list.append(label_int[subjects.index(subject)])\n",
    "embed_list = np.asarray(embed_list)\n",
    "label_list = np.asarray(label_list)\n",
    "# embed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/hd/jbpark/IJB-C_Asian/\"\n",
    "np.save(save_path+'ijbc_embed_vectors.npy', embed_list)\n",
    "np.save(save_path+'ijbc_labels.npy', label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Face Identification Classifer with Dot product & CMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CMC with Top 1 Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from utils import l2_norm\n",
    "%matplotlib inline\n",
    "\n",
    "save_path = \"/hd/jbpark/IJB-C_Asian/\"\n",
    "embed_list = np.load(save_path+'ijbc_embed_vectors.npy')\n",
    "label_list = np.load(save_path+'ijbc_labels.npy')\n",
    "\n",
    "dataset_path = \"/hd/jbpark/IJB-C_Asian/Aligned/\"\n",
    "id_list = os.listdir(dataset_path)\n",
    "id_list.sort()\n",
    "\n",
    "unique_labels = np.unique(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tata Young' 'Kim Tae-hee' 'Ayu Ting Ting' 'Chae Jung-an' 'Nam Bo-ra']\n"
     ]
    }
   ],
   "source": [
    "Rank = 5\n",
    "\n",
    "# org_img_path = 'Test/Kelly Clarkson.jpg'\n",
    "# org_img_path = 'Test/Baby Margaretha.jpg' # Good\n",
    "# org_img_path = 'Test/Gareth Bale.jpg' \n",
    "# org_img_path = 'Test/Kelly Holmes.jpg'\n",
    "# org_img_path = 'Test/Daniele Suzuki.jpg'\n",
    "org_img_path = 'Test/Ayu Ting Ting.jpg'\n",
    "\n",
    "img = cv2.imread(org_img_path)\n",
    "convert_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = cv2.resize(convert_img, (112,112))\n",
    "img = img.astype(np.float32) / 255.\n",
    "\n",
    "if len(img.shape) == 3:\n",
    "    img = np.expand_dims(img, 0)\n",
    "\n",
    "#     print(\"len(img.shape): \"+str(len(img.shape))+ \", img.shape = \"+str(img.shape))\n",
    "embeds = l2_norm(model(img, training=False))\n",
    "\n",
    "\n",
    "dot_sim_list = []\n",
    "temp_sim_list= []\n",
    "for i in unique_labels:\n",
    "    temp_sim_list= []\n",
    "    temp_list = np.where(label_list==i)[0]\n",
    "    for embeding in embed_list[temp_list]:\n",
    "        dot_sim = np.dot(embeds,embeding)\n",
    "        temp_sim_list.append(dot_sim)\n",
    "    dot_sim_list.append(temp_sim_list[np.argmax(temp_sim_list)][0])\n",
    "est = np.argmax(dot_sim_list)\n",
    "\n",
    "df = pd.DataFrame(dot_sim_list)\n",
    "sorted_df = df.sort_values(by=0,ascending=False)\n",
    "estimated_label = np.asarray(sorted_df[:Rank].index)\n",
    "id_list = np.array(id_list)\n",
    "print(id_list[estimated_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>0.779108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>0.758277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.724424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>0.715903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>0.696663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "3252  0.779108\n",
       "1829  0.758277\n",
       "425   0.724424\n",
       "631   0.715903\n",
       "2421  0.696663"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df[:Rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CMC with average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from utils import l2_norm\n",
    "%matplotlib inline\n",
    "\n",
    "save_path = \"/hd/jbpark/IJB-C_Asian/\"\n",
    "embed_list = np.load(save_path+'ijbc_embed_vectors.npy')\n",
    "label_list = np.load(save_path+'ijbc_labels.npy')\n",
    "\n",
    "dataset_path = \"/hd/jbpark/IJB-C_Asian/Aligned/\"\n",
    "id_list = os.listdir(dataset_path)\n",
    "id_list.sort()\n",
    "\n",
    "unique_labels = np.unique(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nam Bo-ra' 'Siti Nurhaliza' 'Nguyễn Thị Kim Ngân' 'Yuni Shara'\n",
      " 'Sameera Reddy']\n"
     ]
    }
   ],
   "source": [
    "Rank = 5\n",
    "\n",
    "# org_img_path = 'Test/Kelly Clarkson.jpg'\n",
    "# org_img_path = 'Test/Baby Margaretha.jpg' # Good\n",
    "# org_img_path = 'Test/Gareth Bale.jpg' \n",
    "# org_img_path = 'Test/Kelly Holmes.jpg'\n",
    "# org_img_path = 'Test/Daniele Suzuki.jpg'\n",
    "org_img_path = 'Test/Ayu Ting Ting.jpg'\n",
    "\n",
    "img = cv2.imread(org_img_path)\n",
    "convert_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = cv2.resize(convert_img, (112,112))\n",
    "img = img.astype(np.float32) / 255.\n",
    "\n",
    "if len(img.shape) == 3:\n",
    "    img = np.expand_dims(img, 0)\n",
    "\n",
    "#     print(\"len(img.shape): \"+str(len(img.shape))+ \", img.shape = \"+str(img.shape))\n",
    "embeds = l2_norm(model(img, training=False))\n",
    "\n",
    "\n",
    "dot_sim_list = []\n",
    "temp_sim_list= []\n",
    "for i in unique_labels:\n",
    "    temp_sim_list= []\n",
    "    temp_list = np.where(label_list==i)[0]\n",
    "    for embeding in embed_list[temp_list]:\n",
    "        dot_sim = np.dot(embeds,embeding)\n",
    "        temp_sim_list.append(dot_sim)\n",
    "    dot_sim_list.append(np.average(temp_sim_list,axis=0))\n",
    "est = np.argmax(dot_sim_list)\n",
    "\n",
    "df = pd.DataFrame(dot_sim_list)\n",
    "sorted_df = df.sort_values(by=0,ascending=False)\n",
    "estimated_label = np.asarray(sorted_df[:Rank].index)\n",
    "id_list = np.array(id_list)\n",
    "print(id_list[estimated_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>0.703205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.653246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>0.645726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>0.633721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>0.605781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "1680  0.703205\n",
       "199   0.653246\n",
       "575   0.645726\n",
       "3134  0.633721\n",
       "1191  0.605781"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df[:Rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Face Identification Classifer with Euclidean distance & CMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CMC with Top 1 Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from utils import l2_norm\n",
    "%matplotlib inline\n",
    "\n",
    "save_path = \"/hd/jbpark/IJB-C_Asian/\"\n",
    "embed_list = np.load(save_path+'ijbc_embed_vectors.npy')\n",
    "label_list = np.load(save_path+'ijbc_labels.npy')\n",
    "\n",
    "dataset_path = \"/hd/jbpark/IJB-C_Asian/Aligned/\"\n",
    "id_list = os.listdir(dataset_path)\n",
    "id_list.sort()\n",
    "\n",
    "unique_labels = np.unique(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Siti Nurhaliza' 'Nguyễn Thị Kim Ngân' 'Yuni Shara' 'Sameera Reddy'\n",
      " 'Burcu Esmersoy']\n"
     ]
    }
   ],
   "source": [
    "Rank = 5\n",
    "\n",
    "# org_img_path = 'Test/Kelly Clarkson.jpg'\n",
    "# org_img_path = 'Test/Baby Margaretha.jpg' # Good\n",
    "# org_img_path = 'Test/Gareth Bale.jpg' \n",
    "# org_img_path = 'Test/Kelly Holmes.jpg'\n",
    "# org_img_path = 'Test/Daniele Suzuki.jpg'\n",
    "org_img_path = 'Test/Ayu Ting Ting.jpg'\n",
    "\n",
    "img = cv2.imread(org_img_path)\n",
    "convert_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = cv2.resize(convert_img, (112,112))\n",
    "img = img.astype(np.float32) / 255.\n",
    "\n",
    "if len(img.shape) == 3:\n",
    "    img = np.expand_dims(img, 0)\n",
    "\n",
    "#     print(\"len(img.shape): \"+str(len(img.shape))+ \", img.shape = \"+str(img.shape))\n",
    "embeds = l2_norm(model(img, training=False))\n",
    "\n",
    "\n",
    "dot_sim_list = []\n",
    "temp_sim_list= []\n",
    "for i in unique_labels:\n",
    "    temp_sim_list= []\n",
    "    temp_list = np.where(label_list==i)[0]\n",
    "    for embeding in embed_list[temp_list]:\n",
    "        temp_sim_list.append(np.linalg.norm(embeds-embeding))\n",
    "    dot_sim_list.append(temp_sim_list[np.argmax(temp_sim_list)])\n",
    "est = np.argmax(dot_sim_list)\n",
    "\n",
    "df = pd.DataFrame(dot_sim_list)\n",
    "sorted_df = df.sort_values(by=0,ascending=True)\n",
    "estimated_label = np.asarray(sorted_df[:Rank].index)\n",
    "id_list = np.array(id_list)\n",
    "print(id_list[estimated_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>0.770448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.831066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>0.841753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>0.855896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>0.883148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "1680  0.770448\n",
       "199   0.831066\n",
       "575   0.841753\n",
       "3134  0.855896\n",
       "1191  0.883148"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df[:Rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CMC with average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from utils import l2_norm\n",
    "%matplotlib inline\n",
    "\n",
    "save_path = \"/hd/jbpark/IJB-C_Asian/\"\n",
    "embed_list = np.load(save_path+'ijbc_embed_vectors.npy')\n",
    "label_list = np.load(save_path+'ijbc_labels.npy')\n",
    "\n",
    "dataset_path = \"/hd/jbpark/IJB-C_Asian/Aligned/\"\n",
    "id_list = os.listdir(dataset_path)\n",
    "id_list.sort()\n",
    "\n",
    "unique_labels = np.unique(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nam Bo-ra' 'Siti Nurhaliza' 'Nguyễn Thị Kim Ngân' 'Yuni Shara'\n",
      " 'Sameera Reddy']\n"
     ]
    }
   ],
   "source": [
    "Rank = 5\n",
    "\n",
    "# org_img_path = 'Test/Kelly Clarkson.jpg'\n",
    "# org_img_path = 'Test/Baby Margaretha.jpg' # Good\n",
    "# org_img_path = 'Test/Gareth Bale.jpg' \n",
    "# org_img_path = 'Test/Kelly Holmes.jpg'\n",
    "# org_img_path = 'Test/Daniele Suzuki.jpg'\n",
    "org_img_path = 'Test/Ayu Ting Ting.jpg'\n",
    "\n",
    "img = cv2.imread(org_img_path)\n",
    "convert_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = cv2.resize(convert_img, (112,112))\n",
    "img = img.astype(np.float32) / 255.\n",
    "\n",
    "if len(img.shape) == 3:\n",
    "    img = np.expand_dims(img, 0)\n",
    "\n",
    "#     print(\"len(img.shape): \"+str(len(img.shape))+ \", img.shape = \"+str(img.shape))\n",
    "embeds = l2_norm(model(img, training=False))\n",
    "\n",
    "\n",
    "dot_sim_list = []\n",
    "temp_sim_list= []\n",
    "for i in unique_labels:\n",
    "    temp_sim_list= []\n",
    "    temp_list = np.where(label_list==i)[0]\n",
    "    for embeding in embed_list[temp_list]:\n",
    "        temp_sim_list.append(np.linalg.norm(embeds-embeding))\n",
    "    dot_sim_list.append(np.average(temp_sim_list,axis=0))\n",
    "est = np.argmax(dot_sim_list)\n",
    "\n",
    "df = pd.DataFrame(dot_sim_list)\n",
    "sorted_df = df.sort_values(by=0,ascending=True)\n",
    "estimated_label = np.asarray(sorted_df[:Rank].index)\n",
    "id_list = np.array(id_list)\n",
    "print(id_list[estimated_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>0.862392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>0.870074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>0.873376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>0.878371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.880157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "3109  0.862392\n",
       "2492  0.870074\n",
       "3534  0.873376\n",
       "2963  0.878371\n",
       "561   0.880157"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df[:Rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Face Identification Classifer with Cosine Similarity & CMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CMC with Top 1 Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from utils import l2_norm\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "save_path = \"/hd/jbpark/dataset/IJB-C_Asian/\"\n",
    "embed_list = np.load(save_path+'ijbc_embed_vectors.npy')\n",
    "label_list = np.load(save_path+'ijbc_labels.npy')\n",
    "\n",
    "dataset_path = \"/hd/jbpark/dataset/IJB-C_Asian/Aligned/\"\n",
    "id_list = os.listdir(dataset_path)\n",
    "id_list.sort()\n",
    "\n",
    "unique_labels = np.unique(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tata Young' 'Kim Tae-hee' 'Ayu Ting Ting' 'Chae Jung-an' 'Nam Bo-ra']\n"
     ]
    }
   ],
   "source": [
    "Rank = 5\n",
    "\n",
    "# org_img_path = 'Test/Kelly Clarkson.jpg'\n",
    "# org_img_path = 'Test/Baby Margaretha.jpg' # Good\n",
    "# org_img_path = 'Test/Gareth Bale.jpg' \n",
    "# org_img_path = 'Test/Kelly Holmes.jpg'\n",
    "# org_img_path = 'Test/Daniele Suzuki.jpg'\n",
    "org_img_path = 'Test/Ayu Ting Ting.jpg'\n",
    "\n",
    "img = cv2.imread(org_img_path)\n",
    "convert_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = cv2.resize(convert_img, (112,112))\n",
    "img = img.astype(np.float32) / 255.\n",
    "\n",
    "if len(img.shape) == 3:\n",
    "    img = np.expand_dims(img, 0)\n",
    "\n",
    "#     print(\"len(img.shape): \"+str(len(img.shape))+ \", img.shape = \"+str(img.shape))\n",
    "embeds = l2_norm(model(img, training=False))\n",
    "\n",
    "\n",
    "dot_sim_list = []\n",
    "temp_sim_list= []\n",
    "for i in unique_labels:\n",
    "    temp_sim_list= []\n",
    "    temp_list = np.where(label_list==i)[0]\n",
    "    for embeding in embed_list[temp_list]:\n",
    "        temp_sim_list.append(np.dot(embeds,embeding)/(np.linalg.norm(embeds)*np.linalg.norm(embeding)))\n",
    "    dot_sim_list.append(temp_sim_list[np.argmax(temp_sim_list)])\n",
    "est = np.argmax(dot_sim_list)\n",
    "\n",
    "df = pd.DataFrame(dot_sim_list)\n",
    "sorted_df = df.sort_values(by=0,ascending=False)\n",
    "estimated_label = np.asarray(sorted_df[:Rank].index)\n",
    "id_list = np.array(id_list)\n",
    "print(id_list[estimated_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CMC with average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from utils import l2_norm\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "save_path = \"/hd/jbpark/dataset/IJB-C_Asian/\"\n",
    "embed_list = np.load(save_path+'ijbc_embed_vectors.npy')\n",
    "label_list = np.load(save_path+'ijbc_labels.npy')\n",
    "\n",
    "dataset_path = \"/hd/jbpark/dataset/IJB-C_Asian/Aligned/\"\n",
    "id_list = os.listdir(dataset_path)\n",
    "id_list.sort()\n",
    "\n",
    "unique_labels = np.unique(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pedro Rodríguez' 'Gareth Bale' 'Carl Hester' 'Islam Slimani'\n",
      " 'Jorge Linares']\n"
     ]
    }
   ],
   "source": [
    "Rank = 5\n",
    "\n",
    "# org_img_path = 'Test/Kelly Clarkson.jpg'\n",
    "# org_img_path = 'Test/Baby Margaretha.jpg' # Good\n",
    "org_img_path = 'Test/Gareth Bale.jpg' \n",
    "# org_img_path = 'Test/Kelly Holmes.jpg'\n",
    "# org_img_path = 'Test/Daniele Suzuki.jpg'\n",
    "# org_img_path = 'Test/Ayu Ting Ting.jpg'\n",
    "\n",
    "img = cv2.imread(org_img_path)\n",
    "convert_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = cv2.resize(convert_img, (112,112))\n",
    "img = img.astype(np.float32) / 255.\n",
    "\n",
    "if len(img.shape) == 3:\n",
    "    img = np.expand_dims(img, 0)\n",
    "\n",
    "#     print(\"len(img.shape): \"+str(len(img.shape))+ \", img.shape = \"+str(img.shape))\n",
    "embeds = l2_norm(model(img, training=False))\n",
    "\n",
    "\n",
    "dot_sim_list = []\n",
    "temp_sim_list= []\n",
    "for i in unique_labels:\n",
    "    temp_sim_list= []\n",
    "    temp_list = np.where(label_list==i)[0]\n",
    "    for embeding in embed_list[temp_list]:\n",
    "        temp_sim_list.append(np.dot(embeds,embeding)/(np.linalg.norm(embeds)*np.linalg.norm(embeding)))\n",
    "    dot_sim_list.append(np.average(temp_sim_list,axis=0))\n",
    "est = np.argmax(dot_sim_list)\n",
    "\n",
    "df = pd.DataFrame(dot_sim_list)\n",
    "sorted_df = df.sort_values(by=0,ascending=False)\n",
    "estimated_label = np.asarray(sorted_df[:Rank].index)\n",
    "id_list = np.array(id_list)\n",
    "print(id_list[estimated_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
