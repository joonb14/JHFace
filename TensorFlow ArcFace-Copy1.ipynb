{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow ArcFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref https://github.com/peteryuX/arcface-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from models import ArcFaceModel\n",
    "# from losses import SoftmaxLoss\n",
    "from losses import softmax_loss\n",
    "import dataset\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"s\n",
    "\n",
    "gpu_num = 0\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CurHead\n",
      "ResNet101V2\n",
      "projection head: False\n",
      "Adam: False\n",
      "epoch: 100\n",
      "batch size: 128\n",
      "Learning Rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "### IJB-C Dataset\n",
    "# batch_size = 128\n",
    "# input_size = 112\n",
    "# embd_shape = 512\n",
    "# head_type = 'ArcHead'\n",
    "# backbone_type = 'MobileNetV2'\n",
    "# w_decay=5e-4\n",
    "# num_classes = 3584 \n",
    "# base_lr = 0.01\n",
    "# dataset_len = 13033 \n",
    "# epochs = 100\n",
    "# steps_per_epoch = dataset_len // batch_size\n",
    "\n",
    "### MS1M dataset\n",
    "num_classes = 85742 \n",
    "dataset_len = 5822653\n",
    "batch_size = 128 # Initially 128\n",
    "input_size = 112\n",
    "embd_shape = 512\n",
    "train_size = int(0.8 * dataset_len)\n",
    "steps_per_epoch = train_size // batch_size\n",
    "val_size = dataset_len - train_size\n",
    "validation_steps = val_size // batch_size\n",
    "\n",
    "w_decay=5e-4\n",
    "epochs = 100\n",
    "\n",
    "save_steps = 1000\n",
    "steps = 1\n",
    "is_ccrop=False\n",
    "binary_img=True\n",
    "\n",
    "is_Adam = False   # True\n",
    "projection_head = False  # False\n",
    "dgx = True\n",
    "\n",
    "head_type = 'CurHead' # ''ArcHead', CosHead', 'SphereHead', 'CurHead'\n",
    "# Backbones w/ pretrained weights:\n",
    "#     MobileNet, MobileNetV2, InceptionResNetV2, InceptionV3, ResNet50, ResNet50V2, ResNet101V2, NASNetLarge, NASNetMobile, Xception, MobileNetV3Large, MobileNetV3Small, EfficientNetLite0~6, EfficientNetB0~7\n",
    "# Backbones w/o pretrained weights:\n",
    "#      MnasNetA1, MnasNetB1, MnasNetSmall \n",
    "backbone_type = 'ResNet101V2' \n",
    "\n",
    "if head_type == 'SphereHead':\n",
    "    base_lr = 0.01 \n",
    "    margin = 1.35\n",
    "    logist_scale = 30.0 \n",
    "elif head_type == 'CosHead':\n",
    "    base_lr = 0.01 \n",
    "    margin=0.35\n",
    "    logist_scale=64\n",
    "elif head_type == 'ArcHead':\n",
    "#     base_lr = 0.01 \n",
    "    base_lr = 0.1 \n",
    "    margin=0.5\n",
    "    logist_scale=64\n",
    "elif head_type == 'CurHead':\n",
    "    base_lr = 0.01 \n",
    "    margin=0.5\n",
    "    logist_scale=64\n",
    "else:\n",
    "    base_lr = 0.01 # initially 0.01\n",
    "    \n",
    "print(head_type)\n",
    "print(backbone_type)\n",
    "print(\"projection head:\", projection_head)\n",
    "print(\"Adam:\", is_Adam)\n",
    "print(\"epoch:\", epochs)\n",
    "print(\"batch size:\", batch_size)\n",
    "print(\"Learning Rate:\", base_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"arcface_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet101v2 (Functional)        (None, 4, 4, 2048)   42626560    input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "OutputLayer (Functional)        (None, 512)          16787968    resnet101v2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "label (InputLayer)              [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CurHead (Functional)            (None, 85742)        43899905    OutputLayer[0][0]                \n",
      "                                                                 label[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 103,314,433\n",
      "Trainable params: 103,211,648\n",
      "Non-trainable params: 102,785\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train_data_dir = \"/raid/workspace/jbpark/IJB-C_Asian/\"\n",
    "# tfrecord_name = train_data_dir+'ijbc_bin.tfrecord'\n",
    "if dgx:\n",
    "    train_data_dir = \"/raid/workspace/jbpark/ms1m/\"\n",
    "    tfrecord_name = f'{train_data_dir}ms1m_bin.tfrecord'\n",
    "else:\n",
    "    train_data_dir = \"/hd/jbpark/dataset/ms1m/\"\n",
    "    tfrecord_name = f'{train_data_dir}ms1m_bin.tfrecord'\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = dataset.load_tfrecord_dataset(\n",
    "    tfrecord_name, batch_size, train_size=train_size, binary_img=binary_img, \n",
    "    is_ccrop=is_ccrop)\n",
    "\n",
    "# print(\"data: \", train_dataset)\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[f\"/gpu:{gpu_num}\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "with strategy.scope():\n",
    "    model = ArcFaceModel(size=input_size,\n",
    "                             backbone_type=backbone_type,\n",
    "                             num_classes=num_classes,\n",
    "                             margin=margin, \n",
    "                             logist_scale=logist_scale,\n",
    "                             head_type=head_type,\n",
    "                             embd_shape=embd_shape,\n",
    "                             w_decay=w_decay,\n",
    "                             training=True) #projection_head = projection_head\n",
    "    model.summary()\n",
    "\n",
    "    learning_rate = tf.constant(base_lr)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate,\n",
    "                                                                 decay_steps=60000, \n",
    "                                                   decay_rate=0.1,staircase=True)\n",
    "    if is_Adam:\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=lr_schedule)\n",
    "    else:\n",
    "#         optimizer = tf.keras.optimizers.SGD(\n",
    "#             learning_rate=learning_rate, momentum=0.9)\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=lr_schedule, momentum=0.9)\n",
    "\n",
    "    loss_fn = softmax_loss\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1000/36391 [..............................] - ETA: 1:38:54 - loss: 42.9008\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_42.10417175292969.ckpt\n",
      " 2000/36391 [>.............................] - ETA: 1:34:46 - loss: 42.1356\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_40.752777099609375.ckpt\n",
      " 3000/36391 [=>............................] - ETA: 1:30:57 - loss: 41.5258\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_39.898773193359375.ckpt\n",
      " 4000/36391 [==>...........................] - ETA: 1:27:57 - loss: 41.0347\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_39.25187683105469.ckpt\n",
      " 5000/36391 [===>..........................] - ETA: 1:24:52 - loss: 40.6254\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_38.74100112915039.ckpt\n",
      " 6000/36391 [===>..........................] - ETA: 1:22:26 - loss: 40.2741\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_38.30036544799805.ckpt\n",
      " 7000/36391 [====>.........................] - ETA: 1:19:30 - loss: 39.9623\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_37.8880615234375.ckpt\n",
      " 8000/36391 [=====>........................] - ETA: 1:16:34 - loss: 39.6780\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_37.49032974243164.ckpt\n",
      " 9000/36391 [======>.......................] - ETA: 1:13:48 - loss: 39.4136\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_37.108970642089844.ckpt\n",
      "10000/36391 [=======>......................] - ETA: 1:11:08 - loss: 39.1643\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_36.73511505126953.ckpt\n",
      "11000/36391 [========>.....................] - ETA: 1:08:25 - loss: 38.9273\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_36.38386535644531.ckpt\n",
      "12000/36391 [========>.....................] - ETA: 1:05:41 - loss: 38.7009\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_36.04396057128906.ckpt\n",
      "13000/36391 [=========>....................] - ETA: 1:02:49 - loss: 38.4842\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_35.724552154541016.ckpt\n",
      "14000/36391 [==========>...................] - ETA: 1:00:11 - loss: 38.2761\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_35.41971969604492.ckpt\n",
      "15000/36391 [===========>..................] - ETA: 57:30 - loss: 38.0759\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_35.12611389160156.ckpt\n",
      "16000/36391 [============>.................] - ETA: 54:48 - loss: 37.8823\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_34.83150863647461.ckpt\n",
      "17000/36391 [=============>................] - ETA: 52:10 - loss: 37.6943\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_34.54264831542969.ckpt\n",
      "18000/36391 [=============>................] - ETA: 49:26 - loss: 37.5115\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_34.26545715332031.ckpt\n",
      "19000/36391 [==============>...............] - ETA: 46:43 - loss: 37.3334\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_33.991397857666016.ckpt\n",
      "20000/36391 [===============>..............] - ETA: 44:00 - loss: 37.1595\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_33.71991729736328.ckpt\n",
      "21000/36391 [================>.............] - ETA: 41:20 - loss: 36.9894\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_33.45711135864258.ckpt\n",
      "22000/36391 [=================>............] - ETA: 38:38 - loss: 36.8229\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_33.194461822509766.ckpt\n",
      "23000/36391 [=================>............] - ETA: 35:54 - loss: 36.6595\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_32.937625885009766.ckpt\n",
      "24000/36391 [==================>...........] - ETA: 33:13 - loss: 36.4991\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_32.68204879760742.ckpt\n",
      "25000/36391 [===================>..........] - ETA: 30:34 - loss: 36.3414\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_32.43586349487305.ckpt\n",
      "26000/36391 [====================>.........] - ETA: 27:51 - loss: 36.1866\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_32.19972610473633.ckpt\n",
      "27000/36391 [=====================>........] - ETA: 25:13 - loss: 36.0345\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_31.957691192626953.ckpt\n",
      "28000/36391 [======================>.......] - ETA: 22:35 - loss: 35.8846\n",
      "Epoch 00001: saving model to /raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/ms1m_ResNet101V2_CurHead_check/SGD/e_1_l_31.715259552001953.ckpt\n",
      "28599/36391 [======================>.......] - ETA: 20:59 - loss: 35.7957"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "if dgx:\n",
    "    base_dir = \"/raid/workspace/honghee/FaceRecognition/\"\n",
    "    if projection_head:\n",
    "        save_name = f'ms1m_{backbone_type}_{head_type}_ProjectionHead_check/'\n",
    "    else:\n",
    "        save_name = f'ms1m_{backbone_type}_{head_type}_check/'\n",
    "else:\n",
    "    base_dir = \"/hd/honghee/models/\"\n",
    "    save_name = f'ms1m_{backbone_type}_{head_type}_check/'\n",
    "\n",
    "if is_Adam:\n",
    "    version = \"Adam\"\n",
    "else:\n",
    "    version = \"SGD\"\n",
    "\n",
    "Path(f'{base_dir}checkpoints/w_tfidentity/{save_name}{version}').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "### MS1M dataset\n",
    "tb_callback = TensorBoard(log_dir='logs/arcface/',\n",
    "                                  update_freq = batch_size * 5,\n",
    "                                  profile_batch=0)\n",
    "tb_callback._total_batches_seen = steps\n",
    "tb_callback._samples_seen = steps * batch_size\n",
    "check_dir = f'{base_dir}checkpoints/w_tfidentity/{save_name}{version}'\n",
    "mc_callback = ModelCheckpoint(\n",
    "            check_dir+'/e_{epoch}_l_{loss}.ckpt',\n",
    "            save_freq = save_steps, verbose=1,\n",
    "            save_weights_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# callbacks = [mc_callback, tb_callback]\n",
    "callbacks = [mc_callback, tb_callback, early_stopping]\n",
    "# callbacks = [mc_callback, tb_callback, early_stopping, lr_scheduler]\n",
    "\n",
    "### IJB-C Dataset\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint(\n",
    "#         base_dir+\"checkpoints/\"+save_name+\".ckpt\", \n",
    "# #         monitor='val_accuracy', \n",
    "#         monitor='loss', \n",
    "#         verbose=1, \n",
    "#         save_best_only=True, \n",
    "#         save_weights_only = True,\n",
    "#         mode='min'\n",
    "#     ),\n",
    "#     EarlyStopping(\n",
    "# #         monitor='val_accuracy', \n",
    "#         monitor='loss', \n",
    "#         patience=15, \n",
    "#         min_delta=0.001, \n",
    "#         mode='min'\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume training with latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "if is_Adam:\n",
    "    version = \"Adam\"\n",
    "else:\n",
    "    version = \"SGD\"\n",
    "\n",
    "if dgx:\n",
    "    base_dir = \"/raid/workspace/honghee/FaceRecognition/checkpoints/w_tfidentity/\"\n",
    "    # save_name = \"ms1m_mobilenet_check/SGD/*\"\n",
    "    if projection_head:\n",
    "        save_name = f'ms1m_{backbone_type}_{head_type}_ProjectionHead_check/{version}/*'\n",
    "    else:\n",
    "        save_name = f'ms1m_{backbone_type}_{head_type}_check/{version}/*'\n",
    "else:\n",
    "    base_dir = \"/hd/honghee/models/checkpoints/w_tfidentity/\"\n",
    "    save_name = f'ms1m_{backbone_type}_{head_type}_check/{version}/*'\n",
    "file_list = []\n",
    "for files in glob(f'{base_dir}{save_name}'):\n",
    "    file_list.append(files.split('/')[-1].split('l_')[-1])\n",
    "file_list.sort()\n",
    "\n",
    "load_file_name = []\n",
    "for files in glob(f'{base_dir}{save_name}'):\n",
    "    if file_list[0] == files.split('/')[-1].split('l_')[-1]:\n",
    "        load_file_name = files\n",
    "best_checkpoint = load_file_name.split('.data')[0]\n",
    "initial_epoch = int(load_file_name.split('e_')[-1].split('_')[0])-1\n",
    "print(initial_epoch)\n",
    "print(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_dir = \"/raid/workspace/jbpark/IJB-C_Asian/\"\n",
    "# tfrecord_name = train_data_dir+'ijbc_bin.tfrecord'\n",
    "\n",
    "if dgx:\n",
    "    train_data_dir = \"/raid/workspace/jbpark/ms1m/\"\n",
    "    tfrecord_name = f'{train_data_dir}ms1m_bin.tfrecord'\n",
    "else:\n",
    "    train_data_dir = \"/hd/jbpark/dataset/ms1m/\"\n",
    "    tfrecord_name = f'{train_data_dir}ms1m_bin.tfrecord'\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = dataset.load_tfrecord_dataset(\n",
    "    tfrecord_name, batch_size, train_size=train_size, binary_img=binary_img,\n",
    "    is_ccrop=is_ccrop)\n",
    "\n",
    "if dgx:\n",
    "    base_dir = \"/raid/workspace/honghee/FaceRecognition/\"\n",
    "    if projection_head:\n",
    "        save_name = f'ms1m_{backbone_type}_{head_type}_ProjectionHead_check/'\n",
    "    else:\n",
    "        save_name = f'ms1m_{backbone_type}_{head_type}_check/'\n",
    "else:\n",
    "    base_dir = \"/hd/honghee/models/\"\n",
    "    save_name = f'ms1m_{backbone_type}_{head_type}_check/'\n",
    "\n",
    "Path(f'{base_dir}checkpoints/w_tfidentity/{save_name}{version}').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:{gpu_num}\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    model = ArcFaceModel(size=input_size,\n",
    "                             backbone_type=backbone_type,\n",
    "                             num_classes=num_classes,\n",
    "                             head_type=head_type,\n",
    "                             embd_shape=embd_shape,\n",
    "                             w_decay=w_decay,\n",
    "                             training=True,\n",
    "                             projection_head=projection_head)\n",
    "    model.load_weights(best_checkpoint)\n",
    "\n",
    "    learning_rate = tf.constant(base_lr)\n",
    "    if is_Adam:\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate)\n",
    "\n",
    "    loss_fn = softmax_loss\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "    model.summary()\n",
    "    \n",
    "tb_callback = TensorBoard(log_dir='logs/arcface/',\n",
    "                                  update_freq = batch_size * 5,\n",
    "                                  profile_batch=0)\n",
    "tb_callback._total_batches_seen = steps\n",
    "tb_callback._samples_seen = steps * batch_size\n",
    "check_dir = f'{base_dir}checkpoints/w_tfidentity/{save_name}{version}'\n",
    "mc_callback = ModelCheckpoint(\n",
    "            check_dir+'/e_{epoch}_l_{loss}.ckpt',\n",
    "            save_freq = save_steps, verbose=1,\n",
    "            save_weights_only=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=1, min_lr=0.001)\n",
    "# callbacks = [mc_callback, tb_callback,reduce_lr]\n",
    "callbacks = [mc_callback, tb_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs, \n",
    "    initial_epoch=initial_epoch,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
